\section{Задача}

\vspace{-\baselineskip}

\subsection{Баєсова задача розпізнавання}

Поставимо баєсову задачу розпізнавання \cite{Duda:Hart:1973}.
Для цього потрібно визначитися з функцією витрат
\cite{berger1980}
\begin{equation*}
  W: X \times X \rightarrow \mathbb{R}.
\end{equation*}
Стратегію
\begin{equation*}
  q: T \rightarrow X,
\end{equation*}
яка для зображення $t$ дає результат $x$, позначимо
\begin{equation*}
  q\left( t \right) = x.
\end{equation*}
Математичне сподівання функції витрат $W$
як функції випадкової пари $\left\langle t, x \right\rangle$
для даного вирішального правила $q$ називається баєсовим ризиком
\cite{wald1955selected}
\begin{equation*}
  R_{\theta} \left( q \right)
  = \int\limits_{T, X}
    W \left( x, q\left( t \right) \right)
    d F_{\theta}\left( t, x \right)
  = \Meanof{\theta}{W\left( x, q\left( t \right) \right)},
\end{equation*}
де $F_{\theta}$~---~функція сумісного розподілу зображення
та параметрів зображеної моделі при відомих $\theta$.

\subsection{Баєсова стратегія}

Стратегія $q^*$ називається баєсовою,
якщо може бути представлена у вигляді \cite{schlezinger:2013}
\begin{equation}\label{eq:bayesian}
  q^*
  = \argmin\limits_{q \in Q}
    \sum_{\theta \in \Theta}
      \tau\left( \theta \right) \cdot R_{\theta}\left( q \right),
  \qquad
  \tau\left( \theta \right) \ge 0,
  \qquad
  \sum_{\theta \in \Theta} \tau\left( \theta \right) = 1.
\end{equation}
Стратегії іншого вигляду є негодящими:
якщо $q_0$~---~стратегія,
яку не можна представити у вигляді \eqref{eq:bayesian},
обов'язково знайдеться баєсова стратегія $q$ така, що
при будь-якому значенні параметрів $\theta$
небаєсова стратегія буде розпізнавати гірше за певну баєсову
\begin{equation*}
  R_{\theta}\left( q_0 \right) > R_{\theta}\left( q \right), \qquad
  \forall \theta \in \Theta.
\end{equation*}

Оскільки зовнішній вигляд найкращих стратегій декларовано,
для кожної задачі треба шукати лише коефіцієнти $\tau\left( \theta \right)$.
Прикладом доцільної задачі у даному випадку
може бути пошук такої стратегії,
що помиляється якнайменше при кожному $\theta$.
За визначенням мінімальні витрати гарантує та стратегія,
якій заздалегідь відомо параметр $\theta$, з яким вона працюватиме.
Така стратегія називається оптимальною
\begin{equation}\label{eq:problem:bayesian:optimal}
  q^{\theta}\left( t \right)
  = \argmin\limits_{q \in Q} R_{\theta}\left( q \right).
\end{equation}
Можемо сформулювати оптимізаційну задачу з обмеженнями
\begin{equation}\label{eq:problem:bayesian:suboptimal}
  \begin{cases}
    c \to \min, \\
    R_{\theta}\left( q \right)
      - R_{\theta}\left( q^{\theta} \right) < c,
    \qquad \forall \theta \in \Theta.
  \end{cases}
\end{equation}
В результаті розв'язку отримаємо ваги $\tau\left( \theta \right)$
і стратегію $q$.
Доведемо від протилежного, що знайдена стратегія не буде негодящою:
якщо знайдеться інша стратегія $q'$, яка краща за дану $q$,
то знайдеться таке невід'ємне $\delta$, що
\begin{equation*}
  R_{\theta}\left( q' \right)
    - R_{\theta}\left( q^{\theta} \right) < c - \delta,
  \qquad \forall \theta \in \Theta.
\end{equation*}
Якщо таке $\delta > 0$ існує, то $c$ можна зменшити на $\delta$
і оптимізаційну задачу \eqref{eq:problem:bayesian:suboptimal}
не було розв'язано до кінця.
Проте $\delta$ може бути наперед визначеною точністю обчислень,
якою можна поступитися на користь швидкості розв'язку.
Стратегія, що є розв'язком \eqref{eq:problem:bayesian:suboptimal},
називається субоптимальною.

Далі зафіксуємо параметр $\theta$, ніби він відомий,
і розглянемо побудову оптимальних стратегій для різних штрафних функцій.

\subsection{Бінарна функція витрат}

Досить розповсюдженою, проте зазвичай неприродною є бінарна штрафна функція
\begin{equation*}
  W \left( x, x' \right)
  = \mathbbm{1} \left( x \neq x' \right).
\end{equation*}
Для неперервного випадку така функція витрат не підходить,
бо баєсів ризик
\begin{equation*}
  R_{\theta}\left( q \right)
  = \sum\limits_{t \in T}
    \int\limits_{x \in X}
    \mathbbm{1} \left( x \neq q\left( t \right) \right)
    \cdot p\left( t, x \right) d\; x
  = 1,\qquad
  \forall q \in Q.
\end{equation*}
Будь-яка стратегія дає невірну відповідь у неперервному випадку
з точки зору бінарної функції витрат,
тому для неї буде розглядатися лише дискретний випадок.

Оберемо стратегію $q^*$,
що мінімізує математичне сподівання цієї функції витрат
\begin{equation*}
  \begin{split}
    q^*_{\theta}\left( t \right)
    = \argmin_{x'} \left\{
      \sum\limits_{x \in X}
        \mathbb{P}\left( t, x \right)
        \cdot \mathbbm{1} \left( x \neq x' \right)
      \right\} = \\
    = \argmin_{x'} \left\{
      \sum\limits_{x \in X}
        \mathbb{P}\left( t, x \right)
      - \sum\limits_{x \in X}
        \mathbb{P}\left( t, x \right)
        \cdot \mathbbm{1} \left( x = x' \right)
      \right\} = \\
    = \argmin_{x'} \left\{
      1 - \mathbb{P}\left( t, x' \right)
      \right\}.
  \end{split}
\end{equation*}
В результаті маємо максимізацію апостеріорної ймовірності,
адже $t$ дано і фіксовано, його ймовірність константа,
і на неї можна поділити
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \argmax_x \mathbb{P} \left( t, x \right)
  = \argmax_x \mathbb{P} \left( x \mcond t \right).
\end{equation*}

Отже, якщо використовується бінарна функція витрат,
потрібно обирати найбільш ймовірний набір параметрів.
Аналітичний вираз для розрахування $f$ досить складний,
тому доведеться скористатися чисельними методами,
які не завжди дають точну відповідь
і можуть зупинитися у точці локального оптимуму,
який часто не співпадає з глобальним у даній задачі.

\subsection{Інтервальна функція витрат}

Більш загальним варіантом бінарної штрафної функції є
індикатор неналежності дійсного параметру $x$
деякому $\delta$-околі обраного параметру $x'$
\begin{equation*}
  W \left( x, x' \right)
  = \mathbbm{1} \left( x \notin \delta\left( x' \right) \right).
\end{equation*}

Оберемо стратегію, що мінімізує математичне сподівання цієї функції витрат
\begin{equation*}
  \begin{split}
    q^*_{\theta}\left( t \right)
    = \argmin_{x'} \left\{
      \int\limits_{X}
        \mathbbm{1} \left( x \notin \delta\left( x' \right) \right)
        d F\left( t, x \right)
      \right\} = \\
    = \argmin_{x'} \left\{
      1 -
      \int\limits_{X}
        \mathbbm{1} \left( x \in \delta\left( x' \right) \right)
        d F\left( t, x \right)
      \right\}
  \end{split}
\end{equation*}
В результаті
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \argmax_{x'} \int\limits_{\delta\left( x' \right)}
    dF_{\theta}\left( t, x \right)
  = \argmax_{x'} \mathbb{P} \left( t, x \in \delta\left( x' \right) \right).
\end{equation*}
Потрібно обрати таку точку,
щоб ймовірність того,
що параметри належать її $\delta$-околу,
була більшою,
ніж для $\delta$-околів інших точок при даному зображенні $t$.

\subsection{Різниця моделей}

Розглянемо більш природню функцію витрат ---
квадрат евклідової відстані між точками дійсної та обраної моделі.
Вона має вигляд
\begin{equation*}
  \begin{split}
    W \left( x, x' \right)
    = \left\| G\left( x \right) - G\left( x' \right) \right\|^2
    = \sum_{v \in V} \left[
        G_v\left( x \right) - G_v\left( x' \right)
      \right]^2 = \\
    = \sum_{v \in V} \sum_{i = 1}^n \left[
        \lambda_i^v \cdot \left( x_i - x'_i \right)
      \right]^2
    = \sum_{i = 1}^n \left\{ \left( x_i - x'_i \right)^2
      \cdot \sum_{v \in V} \left( \lambda_i^v \right)^2 \right\} = \\
    = \left| \beta_i^2 = \sum_{v \in V} \left( \lambda_i^v \right)^2 \right|
    = \sum_{i = 1}^n \beta_i^2 \cdot \left( x_i - x'_i \right)^2.
  \end{split}
\end{equation*}

Оберемо стратегію $q^*$,
що мінімізує математичне сподівання цієї функції витрат
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \argmin_{x'} \left\{
    \int\limits_{X}
        \sum_{i = 1}^n \beta_i^2 \cdot \left( x'_i - x_i \right)^2
        dF_{\theta}\left( t, x \right)
    \right\}.
\end{equation*}
Щоб мінімізувати неперервну функцію від параметрів $x'_i$,
можна взяти по них похідну, бо $x'_i$ не є змінною,
по якій ведеться інтегрування~---~з точки зору інтегралу це лише константа
\begin{equation*}
  \frac{\partial \int\limits_{X}
      \sum\limits_{i = 1}^n \beta_i^2 \cdot \left( x'_i - x_i \right)^2
      dF_{\theta}\left( t, x \right)
  }{\partial x'_i}
  = 2 \cdot \int\limits_{X}
    \beta_i^2 \cdot \left( x'_i - x_i \right) dF_{\theta}\left( t, x \right),
    \qquad i = 1..n
\end{equation*}
та прирівняти до нуля
\begin{equation*}
  \int\limits_{X} \left( x'_i - x_i \right) dF_{\theta}\left( t, x \right) = 0,
  \qquad i = 1..n.
\end{equation*}
Значення компоненти
\begin{equation*}
  x'_i
  = \frac{\int\limits_{X} x_i dF_{\theta}\left( t, x \right)}
         {\int\limits_{X} dF_{\theta}\left( t, x \right)}
  = \frac{\int\limits_{X} x_i dF_{\theta}\left( t, x \right)}
         {\mathbb{P}\left( t \right)}
\end{equation*}
Результуюча стратегія
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \frac{\int\limits_{X} x dF_{\theta}\left( t, x \right)}{\mathbb{P}\left( t \right)}.
\end{equation*}
У вигляді умовного математичного сподівання
\begin{equation*}
  q^*_{\theta}\left( t \right) = \Meanof{\theta}{x \mcond t}.
\end{equation*}

Ділення на ймовірність появи зображення $t$ можна сприймати як нормування
при використанні чисельних методів розрахунку даного інтегралу.

\subsection{Різниця параметрів}

Розглянемо більш просту функцію витрат ---
квадрат евклідової відстані між дійсними та обраними параметрами
моделі зображеного обличчя
\begin{equation*}
  W \left( x, x' \right)
  = \left\| x - x' \right\|^2
  = \sum_{i = 1}^n \left( x_i - x'_i \right)^2.
\end{equation*}

Оберемо стратегію $q^*$,
що мінімізує математичне сподівання цієї функції витрат
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \argmin_{x'} \left\{
    \int\limits_{X}
        \sum_{i = 1}^n \left( x'_i - x_i \right)^2
        dF_{\theta}\left( t, x \right)
    \right\}.
\end{equation*}
Маємо мінімізацію неперервної функції від параметрів $x'_i$,
отже можемо взяти по них похідну
\begin{equation*}
  \frac{\partial \int\limits_{X}
      \sum\limits_{i = 1}^n \left( x'_i - x_i \right)^2
      dF_{\theta}\left( t, x \right)
  }{\partial x'_i}
  = 2 \cdot \int\limits_{x \in X} \left( x'_i - x_i \right)
    dF_{\theta}\left( t, x \right), \qquad i = 1..n
\end{equation*}
та прирівняти до нуля
\begin{equation*}
  \int\limits_{X}
    \left( x'_i - x_i \right) dF_{\theta}\left( t, x \right) = 0, \qquad i = 1..n.
\end{equation*}
Значення компоненти
\begin{equation*}
  x'_i
  = \frac{\int\limits_{X} x_i dF_{\theta}\left( t, x \right)}
         {\int\limits_{X} dF_{\theta}\left( t, x \right)}
  = \frac{\int\limits_{X} x_i dF_{\theta}\left( t, x \right)}
         {\mathbb{P}\left( t \right)}
\end{equation*}
Результуюча стратегія
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \frac{\int\limits_{X} x dF_{\theta}\left( t, x \right)}{\mathbb{P}\left( t \right)}.
\end{equation*}
Оптимальна стратегія як умовне математичне сподівання
\begin{equation*}
  q^*_{\theta}\left( t \right) = \Meanof{\theta}{x \mcond t}.
\end{equation*}

Отримана та ж стратегія,
що мінімізує математичне сподівання суми квадратів різниць
координат вершин дійсної та обраної моделі обличчя.
Тобто це вирішувальне правило розв'язує обидві задачі.

Ділення на ймовірність появи зображення $t$ можна сприймати як нормування
при використанні чисельних методів розрахунку даного інтегралу,
як і в минулому прикладі.
