\section{Задача}

\subsection{Початкові умови}

\subsubsection{Зображення}

Позначимо множину $T$ зображень і множину $C$ кольорів.
Введемо множину $I$ пікселів зображення.
Зображення $t \in T$ є відображення з множини пікселів на множину їх значень
\begin{equation*}
  t: I \rightarrow C.
\end{equation*}
Колір пікселя $i$ в зображенні $t$ позначимо як $t_i$.

Взагалі кажучи, $I$ --- множина індексів матриць однакового розміру
\begin{equation*}
  I = \left\{ \left\langle i, j \right\rangle
    \;\middle|\; i = 1..h,\; j = 1..w \right\}.
\end{equation*}
Зазвичай використовуються зображення розміром від
$100 \times 100 = 10^4$ пікселів.
Проте сучасні камери на фотоапаратах, смартфонах та інших пристроях
можуть зробити зображення площею кілька мільйонів пікселів і більше.
При використанні $2^8 = 256$ градацій сірого маємо
$2^{8 \cdot 10^4} \approx 10^{24 \cdot 10^3}$
різних зображень розміром $100 \times 100$, тобто неймовірно багато.

Тривимірна модель обличчя визначається не тільки набором $n$ дійсних параметрів
з множини $X = \mathbb{R}^n$.
Є додаткові параметри, що відіграють важливу роль при візуалізації,
проте не потрібні в результаті --- поворот, масштаб, перспектива тощо.
Введемо відображення $\theta^M \in \Theta^M$,
що застосовує необхідні перетворення до точки в тривимірному просторі
\begin{equation*}
  \theta^M: \mathbb{R}^3 \rightarrow \mathbb{R}^3.
\end{equation*}
Функцією, що перетворює набір параметрів на зображення, є відображення
\begin{equation*}
  f: \Theta^M \times X \rightarrow T.
\end{equation*}
Зображення $t$, згенероване з параметрами $\theta^M$ та $x$, позначатимемо
\begin{equation*}
  f_{\theta^M} \left( x \right) = t.
\end{equation*}
В подальших записах індекс $\theta^M$ записувати не будемо,
коли з контексту буде зрозуміло, які перетворення застосовуються до моделі.

Для подальших обчислень введемо функцію $h$ (hidden),
яка приймає значення $0$,
якщо в даній точці зображення є піксель обличчя,
та дорівнює $1$ у протилежному випадку
\begin{align*}
  h: \Theta^M \times X \rightarrow \left\{ 0, 1 \right\}.
\end{align*}
Введемо короткий запис для інверсії маски
\begin{align*}
  \overline{h}^{\theta^M}_i\left( x \right)
  = 1 - h^{\theta^M}_i\left( x \right),\qquad
  i \in I.
\end{align*}

\subsubsection{Опорні точки}

Оскільки відповідні вершини всіх моделей мають однакове семантичне значення,
за рахунок чого простір згенерованих облич і є опуклим,
можна скористатися інформацією деяких особливих з точки зору людини точок.
Такі точки як краї губ, носа, очей і таке інше назвемо опорними точками.
Множину обраних точок в контексті певної задачі позначатимемо
\begin{equation*}
  L \subset V.
\end{equation*}
Положення $u$ опорної точки $l \in L$ у моделі $m$ позначимо
\begin{equation*}
  m_{l} = u.
\end{equation*}
Відображення тривимірної точки,
до якої застосовано перетворення $\theta^M$,
\begin{equation*}
  P_2: \Theta^M \times \mathbb{R}^3 \rightarrow I.
\end{equation*}
Проекцію $p$ точки $v$ моделі $m$ на площину запишемо
\begin{equation*}
  P^2_{\theta^M}\left( m_v \right) = p.
\end{equation*}
Також, коли з контексту зрозуміло значення $\theta^M$,
позначатимемо без нижнього індексу
\begin{equation*}
  P^2\left( m_v \right) = p.
\end{equation*}
Введемо відображення $\theta^L$,
що для певної опорної точки $l$
дає координати цієї точки на даному зображенні $t$
\begin{equation*}
  \theta^L: L \times T \rightarrow I.
\end{equation*}
Координати опорної точки $l$ на зображенні $t$ позначимо
\begin{equation*}
  \theta_l^L\left( t \right) = i.
\end{equation*}
Аргумент використовувати не будемо, коли з контексту буде зрозуміло,
про яке зображення йде мова.

Потрібна метрика,
що буде відображати віддаленість двох точок на множині пікселів зображення.
Той факт,
що дві точки $i$ і $i'$ знаходяться одна від одної на відстані $\mu$,
запишемо як
\begin{equation*}
  \left\| i - i' \right\| = \mu.
\end{equation*}
Оскільки $i$ --- впорядкована пара чисел,
що відповідають координатам певного пікселя,
природнім чином можно впровадити звичайну евклідову метрику
для розрахунку відстані між двома точками зображення.

\subsubsection{Фон}
Якщо зображення складається не лише з пікселів обличчя,
обов'язково є фон.
Він може бути відомим, наприклад,
якщо заздалегіть було отримано зображення фону,
на якому буде відбуватися фотозйомка.
У загальному випадку він є невідомою величиною,
розподіл якої також невідомий,
а може не існувати зовсім.
Позначимо його як зображення $\theta^B$
\begin{align*}
  \theta^B \in T.
\end{align*}
Фон має такий самий розмір, як і вхідне зображення.

\subsubsection{Шум}

Вважаємо,
що на вхідне зображення накладено шум $\eta$,
що є вектором незалежних випадкових величин,
розподілених за центрованим нормальним законом
з однаковою невідомою дисперсією $\sigma_t^2$.
Колір пікселя $i$
\begin{equation*}
  t_i = f_i\left( x \right) \cdot \overline{h}_i\left( x \right)
    + \theta_i^B \cdot h_i\left( x \right) + \eta_i,\qquad
  \eta_i \sim \mathcal{N}\left( 0, \sigma^2_t\right), \qquad
  i \in I.
\end{equation*}

Замість реального положення опорних точок $\theta^L$
будемо розглядати її оцінку $\hat{\theta}^L$,
яка отримана з похибкою,
що має центрований гаусовий розподіл
з дисперсією $\sigma^2_L$
\begin{equation*}
  \hat{\theta}^L = \theta_t^L\left( l \right) + \zeta_l,
  \qquad \zeta_l \sim \mathcal{N}\left( 0, \sigma_L^2 \right).
\end{equation*}

Позначимо відхилення проекції опорних точок моделі
від їх оцінки
\begin{align*}
  \Delta\left( x \right)
  = P^2_{\theta^M}\left( G_L\left( x \right) \right) - \hat{\theta}^L.
\end{align*}

Ймовірність того,
що буде пред'явлено зображення $t$ з параметрами $x$
при відомих перетвореннях $\theta^M$
і оцінці положеннь опорних точок $\hat{\theta}^L$, є сумісною ймовірністю
\begin{equation*}
  p_{\theta}
  = \mathbb{P}_{\theta}\left\{
    f_{\theta^M}\left( \xi \right) + \eta = t,
    \zeta = \Delta\left( \xi \right),
    \xi = x
  \right\}.
\end{equation*}
З визначення умовної ймовірності випливає
\begin{equation*}
  p_{\theta}
  = \mathbb{P}_{\theta}\left\{
      f_{\theta^M}\left( \xi \right) + \eta = t,
      \zeta = \Delta\left( \xi \right)
      \;\middle|\; \xi = x \right\}
    \cdot \mathbb{P}\left( \xi = x \right)
\end{equation*}
Позбавимося умовної ймовірності, замінивши $\xi$ на $x$.
Також розіб'ємо перший множник на дві ймовірності,
бо ці події не залежать одна від одної
\begin{equation*}
  p_{\theta}
  = \mathbb{P}_{\theta^M}\left( \eta = t - f_{\theta^M}\left( x \right) \right)
    \cdot \mathbb{P}_{\theta}\left\{
      \zeta = \Delta\left( x \right)
    \right\}
    \cdot \mathbb{P}\left( \xi = x \right).
\end{equation*}

Далі будемо позначати сумісну ймовірність без $\theta$,
коли з контексту буде зрозуміло,
які параметри використані
\begin{align*}
  \mathbb{P}\left( t, x \right) = p_{\theta}.
\end{align*}

\subsection{Узагальнення на випадок кількох зображень}

Пред'явлено кілька зображень
\begin{equation*}
  \vec{t} = \left\langle t_1, t_2, \dots, t_m \right\rangle,
\end{equation*}
на яких знаходиться обличчя однієї й тієї ж самої людини.
Для спрощення вважаємо,
що форма обличчя (і колір шкіри, якщо потрібно)
на всіх зображеннях однаковий, тобто $x = const \in X$.
Цього важко досягти,
якщо обрати фотографії зняті з різних камер в різні пори року,
проте ця вимога має місце,
коли на вході дано відео, фотографії з однієї фотосесії,
фотографії зроблені в один момент з різних ракурсів,
або розрізане зображення, де людину видно у рівних чистих дзеркалах.
Для різних зображень $t^j$ буде відрізнятися
шум $\eta^j$ та параметри зйомки $\theta^j$.

Набір зображень генерується стохастичним автоматом \cite{Rabin:1963}
\begin{equation*}
  \mathfrak{U}_x = \left\langle
    \Theta \times T \times X
      \cup \left\{ \varepsilon_0, \varepsilon \right\}, p, \varepsilon_0,
    \left\{ \varepsilon \right\}
  \right\rangle,
\end{equation*}
де $\varepsilon_0$ --- початковий стан, який не містить ніякої інформації,
а $\varepsilon$ --- кінцевий стан.
Функція $p$ визначає ймовірність того,
що наступним набором параметрів буде $\theta_j$
та згенерується зображення $t_j$.
Якщо зображення не залежать одне від одного
(рис. \ref{fig:solutions:tree-images}),
маємо ймовірності станів,
що не залежать один від одного
\begin{equation*}
  \mathbb{P}_j\left( \theta^j, t^j, x \right)
  = p\left( \theta^j, t^j \right).
\end{equation*}
У випадку відео (рис. \ref{fig:solutions:tree-video})
ймовірноість генерації наступних параметрів та зображення
залежить від поточного стану автомата
\begin{equation*}
  \mathbb{P}_j\left( \theta^j, t^j, x \right)
  = p_j\left( \theta^j, t^j \; \mid \; \theta^{j-1} \right).
\end{equation*}

\begin{figure}[h]
  \centering
  \includestandalone[mode=buildnew]{../tikz/5_40_images_tree}
  \caption{Приклад роботи автомата з незалежними станами}
  \label{fig:solutions:tree-images}
\end{figure}

\begin{figure}[h]
  \centering
  \includestandalone[mode=buildnew]{../tikz/5_40_video_tree}
  \caption{Приклад автомата, що генерує відео}
  \label{fig:solutions:tree-video}
\end{figure}

\subsection{Баєсова задача розпізнавання}

Поставимо баєсову задачу розпізнавання \cite{Anderson:1963}.
Для цього потрібно визначитися з функцією витрат
\cite{berger1980}
\begin{equation*}
  W: X \times X \rightarrow \mathbb{R}.
\end{equation*}
Стратегію $q \in Q$
\begin{equation*}
  q: T \rightarrow X,
\end{equation*}
яка для зображення $t$ дає результат $x$, позначимо
\begin{equation*}
  q\left( t \right) = x.
\end{equation*}
Математичне очікування функції витрат $W$
як функції випадкової пари $\left\langle t, x \right\rangle$
для даного вирішального правила $q$ називається баєсовим ризиком
\cite{wald1955selected}
\begin{equation*}
  R_{\theta} \left( q \right)
  = \sum\limits_{t \in T} \int\limits_{X}
    W \left( x, q\left( t \right) \right)
    d F_{\theta}\left( t, x \right)
    = \Meanof{\theta}{W\left( x, q\left( t \right) \right)},
\end{equation*}
де $F_{\theta}$ --- функція сумісного розподілу зображення
та параметрів зображеної моделі при відомих $\theta$.

Стратегія $q^*$ називається баєсовою,
якщо може бути представлена у вигляді \cite{schlezinger:2013}
\begin{equation}\label{eq:bayesian}
  q^*
  = \argmin\limits_{q \in Q}
    \sum_{\theta \in \Theta}
    \tau\left( \theta \right) \cdot R_{\theta}\left( q \right),
  \qquad
  \tau\left( \theta \right) \ge 0,
  \qquad
  \sum_{\theta \in \Theta} \tau\left( \theta \right) = 1.
\end{equation}
Стратегії іншого вигляду є негодящими:
якщо $q_0$ --- стратегія,
яку не можна представити у вигляді \eqref{eq:bayesian},
обов'язково знайдеться баєсова стратегія $q$ така, що
\begin{equation*}
  R_{\theta}\left( q_0 \right) > R_{\theta}\left( q \right), \qquad
  \forall \theta \in \Theta.
\end{equation*}
Це означає,
що при будь-якому значенні параметрів $\theta$
небаєсова стратегія буде розпізнавати гірше за певну баєсову.

Задача --- знайти таке вирішальне правило $q$,
за якого Баєсів ризик $R_{\theta}\left( q \right)$ мінімальний
для даної функції штрафу $W$ при тих параметрах $\theta$,
що дають найбільший ризик \cite{schlesinger:2002}
\begin{equation*}
  q^* = \argmin_{q \in Q}
        \max\limits_{\theta \in \Theta} R_{\theta}\left( q \right).
\end{equation*}

Оскільки зображення $t$ не залежать одне від одного,
мінімізація і максимізація суми
еквівалентна мінімізації і максимізації кожного її елементу
\begin{equation*}
  q^*\left( t \right)
  = \argmin_{x' \in X} \max\limits_{\theta \in \Theta}
    \int\limits_{X}
    W \left( x, x' \right)
    d F_{\theta}\left( t, x \right).
\end{equation*}
Можна переписати через умовне математичне очікування
\begin{equation*}
  q^*\left( t \right)
  = \argmin_{x' \in X} \max\limits_{\theta \in \Theta}
    \Meanof{\theta}{W\left( x, x' \right) \mcond t }
    \cdot \mathbb{P}\left( t \right).
\end{equation*}
Константний множник не впливає на розв'язок
\begin{equation*}
  q^*\left( t \right)
  = \argmin_{x' \in X} \max\limits_{\theta \in \Theta}
    \Meanof{\theta}{W\left( x, x' \right) \mcond t}.
\end{equation*}

Далі зафіксуємо параметр $\theta$.
Метою цієї дії буде проведення базових математичних обчислень,
що потім будуть використовуватися.
Також це допоможе аналізу існуючих рішень.
Після цих обчислень буде розглянуто,
як саме враховувати вплив невідомих параметрів на розв'язок.

\subsection{Бінарна функція витрат}

Досить розповсюдженою, проте зазвичай неприродною є бінарна штрафна функція
\begin{equation*}
  W \left( x, x' \right)
  = \mathbbm{1} \left( x \neq x' \right).
\end{equation*}
Для неперервного випадку така функція витрат не підходить,
бо баєсів ризик
\begin{equation*}
  R_{\theta}\left( q \right)
  = \sum\limits_{t \in T}
    \int\limits_{x \in X}
    \mathbbm{1} \left( x \neq q\left( t \right) \right)
    \cdot p\left( t, x \right) d\; x
  = 1,\qquad
  \forall q \in Q.
\end{equation*}
Будь-яка стратегія дає невірну відповідь у неперервному випадку
з точки зору бінарної функції витрат,
тому для неї буде розглядатися лише дискретний випадок.

Оберемо стратегію $q^*$,
що мінімізує математичне очікування цієї функції витрат
\begin{equation*}
  \begin{split}
    q^*_{\theta}\left( t \right)
    = \argmin_{x'} \left\{
      \sum\limits_{x \in X}
        \mathbb{P}\left( t, x \right)
        \cdot \mathbbm{1} \left( x \neq x' \right)
      \right\} = \\
    = \argmin_{x'} \left\{
      \sum\limits_{x \in X}
        \mathbb{P}\left( t, x \right)
      - \sum\limits_{x \in X}
        \mathbb{P}\left( t, x \right)
        \cdot \mathbbm{1} \left( x = x' \right)
      \right\} = \\
    = \argmin_{x'} \left\{
      1 - \mathbb{P}\left( t, x' \right)
      \right\}.
  \end{split}
\end{equation*}
В результаті
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \argmax_x \mathbb{P} \left( t, x \right).
\end{equation*}

Отже, якщо використовується бінарна функція витрат,
потрібно обирати найбільш ймовірний набір параметрів.
Аналітичний вираз для розрахування $f$ досить складний,
тому доведеться скористатися чисельними методами,
які не завжди дають точну відповідь
і можуть зупинитися у точці локального отптимуму, якщо такий є
і не співпадає з глобальним.

\subsection{Інтервальна функція витрат}

Більш загальним варіантом бінарної штрафної функції є
індикатор неналежності дійсного параметру $x$
деякій $\delta$-околиці обраного параметру $x'$
\begin{equation*}
  W \left( x, x' \right)
  = \mathbbm{1} \left( x \notin \delta\left( x' \right) \right).
\end{equation*}

Оберемо стратегію, що мінімізує математичне очікування цієї функції витрат
\begin{equation*}
  \begin{split}
    q^*_{\theta}\left( t \right)
    = \argmin_{x'} \left\{
      \int\limits_{X}
        \mathbbm{1} \left( x \notin \delta\left( x' \right) \right)
        d F\left( t, x \right)
      \right\} = \\
    = \argmin_{x'} \left\{
      1 -
      \int\limits_{X}
        \mathbbm{1} \left( x \in \delta\left( x' \right) \right)
        d F\left( t, x \right)
      \right\}
  \end{split}
\end{equation*}
В результаті
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \argmax_{x'} \int\limits_{\delta\left( x' \right)}
    dF_{\theta}\left( t, x \right)
  = \argmax_{x'} \mathbb{P} \left( t, x \in \delta\left( x' \right) \right).
\end{equation*}
Потрібно обрати таку точку,
щоб ймовірність того,
що параметри належать її $\delta$-околиці,
була більшою,
ніж для $\delta$-околиць інших точок при даному зображенні $t$.

\subsection{Різниця моделей}

Розглянемо більш природню функцію витрат ---
квадрат евклідової відстані між точками дійсної та обраної моделі.

Функція витрат має вигляд
\begin{equation*}
  \begin{split}
    W \left( x, x' \right)
    = \left\| G\left( x \right) - G\left( x' \right) \right\|^2
    = \sum_{v \in V} \left[
        G_v\left( x \right) - G_v\left( x' \right)
      \right]^2 = \\
    = \sum_{v \in V} \sum_{i = 1}^n \left[
        \lambda_i^v \cdot \left( x_i - x'_i \right)
      \right]^2
    = \sum_{i = 1}^n \left\{ \left( x_i - x'_i \right)^2
      \cdot \sum_{v \in V} \left( \lambda_i^v \right)^2 \right\} = \\
    = \left| \beta_i^2 = \sum_{v \in V} \left( \lambda_i^v \right)^2 \right|
    = \sum_{i = 1}^n \beta_i^2 \cdot \left( x_i - x'_i \right)^2.
  \end{split}
\end{equation*}

Оберемо стратегію $q^*$,
що мінімізує математичне очікування цієї функції витрат
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \argmin_{x'} \left\{
    \int\limits_{X}
        \sum_{i = 1}^n \beta_i^2 \cdot \left( x'_i - x_i \right)^2
        dF_{\theta}\left( t, x \right)
    \right\}.
\end{equation*}
Щоб мінімізувати неперервну функцію від параметрів $x'_i$,
можна взяти по них похідну
(ми можемо це зробити, бо $x'_i$ не є змінною,
по якій ведеться інтегрування --- з точки зору інтегралу це лише константа)
\begin{equation*}
  \frac{\partial \int\limits_{X}
      \sum\limits_{i = 1}^n \beta_i^2 \cdot \left( x'_i - x_i \right)^2
      dF_{\theta}\left( t, x \right)
  }{\partial x'_i}
  = 2 \cdot \int\limits_{X}
    \beta_i^2 \cdot \left( x'_i - x_i \right) dF_{\theta}\left( t, x \right),
    \qquad i = 1..n
\end{equation*}
та прирівняти до нуля
\begin{equation*}
  \int\limits_{X} \left( x'_i - x_i \right) dF_{\theta}\left( t, x \right) = 0,
  \qquad i = 1..n.
\end{equation*}
Значення компоненти
\begin{equation*}
  x'_i
  = \frac{\int\limits_{X} x_i dF_{\theta}\left( t, x \right)}
         {\int\limits_{X} dF_{\theta}\left( t, x \right)}
  = \frac{\int\limits_{X} x_i dF_{\theta}\left( t, x \right)}
         {\mathbb{P}\left( t \right)}
\end{equation*}
Результуюча стратегія
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \frac{\int\limits_{X} x dF_{\theta}\left( t, x \right)}{\mathbb{P}\left( t \right)}.
\end{equation*}
У вигляді умовного математичного очікування
\begin{equation*}
  q^*_{\theta}\left( t \right) = \Meanof{\theta}{x \mcond t}.
\end{equation*}

Ділення на ймовірність появи зображення $t$ можна сприймати як нормування
при використанні чисельних методів розрахунку даного інтегралу.

\subsection{Різниця параметрів}

Розглянемо більш просту функцію витрат ---
квадрат евклідової норми різниці між дійсними та обраними параметрами
моделі зображеного обличчя
\begin{equation*}
  W \left( x, x' \right)
  = \left\| x - x' \right\|^2
  = \sum_{i = 1}^n \left( x_i - x'_i \right)^2.
\end{equation*}

Оберемо стратегію $q^*$,
що мінімізує математичне очікування цієї функції витрат
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \argmin_{x'} \left\{
    \int\limits_{X}
        \sum_{i = 1}^n \left( x'_i - x_i \right)^2
        dF_{\theta}\left( t, x \right)
    \right\}.
\end{equation*}
Маємо мінімізацію неперервної функції від параметрів $x'_i$,
отже можемо взяти по них похідну
\begin{equation*}
  \frac{\partial \int\limits_{X}
      \sum\limits_{i = 1}^n \left( x'_i - x_i \right)^2
      dF_{\theta}\left( t, x \right)
  }{\partial x'_i}
  = 2 \cdot \int\limits_{x \in X} \left( x'_i - x_i \right)
    dF_{\theta}\left( t, x \right), \qquad i = 1..n
\end{equation*}
та прирівняти до нуля
\begin{equation*}
  \int\limits_{X}
    \left( x'_i - x_i \right) dF_{\theta}\left( t, x \right) = 0, \qquad i = 1..n.
\end{equation*}
Значення компоненти
\begin{equation*}
  x'_i
  = \frac{\int\limits_{X} x_i dF_{\theta}\left( t, x \right)}
         {\int\limits_{X} dF_{\theta}\left( t, x \right)}
  = \frac{\int\limits_{X} x_i dF_{\theta}\left( t, x \right)}
         {\mathbb{P}\left( t \right)}
\end{equation*}
Результуюча стратегія
\begin{equation*}
  q^*_{\theta}\left( t \right)
  = \frac{\int\limits_{X} x dF_{\theta}\left( t, x \right)}{\mathbb{P}\left( t \right)}.
\end{equation*}
Оптимальна стратегія як умовне математичне очікування
\begin{equation*}
  q^*_{\theta}\left( t \right) = \Meanof{\theta}{x \mcond t}.
\end{equation*}

Отримана та ж стратегія,
що мінімізує математичне очікування суми квадратів різниць
координат вершин дійсної та обраної моделі обличчя.
Тобто це вирішувальне правило розв'язує обидві задачі.

Ділення на ймовірність появи зображення $t$ можна сприймати як нормування
при використанні чисельних методів розрахунку даного інтегралу,
як і в минулому прикладі.
